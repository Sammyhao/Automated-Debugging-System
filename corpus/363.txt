 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  There's a Hadoop job I'm trying to run, and when I specify the input as repetitions of my toy data everything works perfectly, however, when I crank it to the whole thing crashes.  My idea is that there isn't anything wrong with the logic of the code, as it works for repetitions but not .  Here is what repetitions of the input data looks like (repetitions are not to be confused with , it rather refers to the number of ones prepended to that long numeric string, i.e. ):  The code of the running job looks like this:  The output for a successful job can be found below:  The full log of the slave node that performed this task can be found here.  Here is the output from an unsuccessful job:  The full output error log, as recorded by the slave node that executed the task, can be found here.  As these jobs are running in uber mode, that should obviate many of the potential causes of this issue- however- as of yet, I've not been able to put my finger on the particular issue- open to all suggestions and insights! :)  Maybe it has something to do with the memory bounds of each individual container?  2,67333 gold badges3232 silver badges6666 bronze badges  6  Its unclear to me what the refers to. Your successful job only processed input record. In the logs for the failed version you can see that the task times out .  I know it is not mandatory to make questions as boring as possible, but I feel like the overhead here is a bit much ;-)  I tried to clarify what I meant by repititions. @DennisJaheruddin yeah I feel you, I tried to chill it out a bit  @BinaryNerd yeah, but the one that takes executes in like 10 seconds, the timeout is a symptom of the issue, not the cause  The first place I would start looking is in your mapper when you are spawning processes with Process proc = Runtime.getRuntime().exec(command); Creating 28 vs 29 new processes could just be the limit on your machine.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  