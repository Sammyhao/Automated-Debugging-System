 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I have the following program which is running in cluster mode of 4 EMR VM  where class is  Now, my runtime error is the following and it happens on the execution of the write command.  The created tokenizedPreprocessedDB is a two columns spark dataframe. <id, array(string)>  What I already tried is:  df.na.fill(...) , to remove every null value even if none was found.  I checked that every "WrappedArray[String]" in the column was actually a WrappedArray and not a String value.  I set the nullable property of the column as false  I also noticed that, trying to run the execution fails with the same error. Removing "repartition by" the error is not thrown by the "println" statement, but the "write" statement throws it.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  