 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I am trying to figure it out with OpenMP. I need to parallelize depth-first traversal.  This is the algorithm:  I try:  Graph "g" is generated and written to the file input.txt. The result of the program is written to the file output.txt.  But this does not work on any number of threads and is much slower. I tried to use but in that case, only one thread works.  The code you posted is not complete, it will not compile. Count the pairing of in main. Provide a minimal reproducible example.  2 Answers 2  A critical section protects a block of code so that no more than one thread can execute it at any given time. Having the recursive call to inside a critical section means that no two tasks could make that call simultaneously. Moreover, since is recursive, any top-level task will have to wait for the entire recursion to finish before it could exit the critical section and allow a task in another thread to execute.  You need to sychronise where it will not interfere with the recursive call and only protect the update to shared data that does not provide its own internal synchronisation. This is the original code:  A naive but still parallel version would be:  Here, the code leaves the critical section as soon as the tasks are created. The problem here is that the entire body of is one critical section, which means that even if there are 1000 recursive calls in parallel, they will execute one after another sequentially and not in parallel. It will even be slower than the sequential version because of the constant cache invalidation and the added OpenMP overhead.  One important note is that OpenMP critical sections, just as regular OpenMP locks, are not re-entrant, so a thread could easily deadlock itself due to encountering the same critical section in a recursive call from inside that same critical section, e.g., if a task gets executed immediately instead of being postponed. It is therefore better to implement a re-entrant critical section using OpenMP nested locks.  The reason for that code being slower than sequential is that it does nothing else except traversing the graph. If it was doing some additional work at each node, e.g., accessing data or computing node-local properties, then this work could be inserted between updating and the loop over the unvisited neighbours:  The parts in the critical sections will still execute sequentially, but the processing represented by will overlap in parallel.  There are tricks to speed things up by reducing the lock contention introduced by having one big lock / critical section. One could, e.g., use a set of OpenMP locks and map the index of onto those locks, e.g., using simple modulo arithmetic as described here. It is also possible to stop creating tasks at certain level of recursion and call a sequential version of instead.  OpenMP is good for data-parallel code, when the amount of work is known in advance. Doesn’t work well for graph algorithms like this one.  If the only thing you do is what’s in your code (push elements into a vector), parallelism is going to make it slower. Even if you have many gigabytes of data on your graph, the bottleneck is memory not compute, multiple CPU cores won’t help. Also, if all threads gonna push results to the same vector, you’ll need synchronization. Also, reading memory recently written by another CPU core is expensive on modern processors, even more so than a cache miss.  If you have some substantial CPU-bound work besides just copying integers, look for alternatives to OpenMP. On Windows, I usually use and APIs. On iOS and OSX, see grand central dispatch. On Linux see cp_thread_pool_create(3) but unlike the other two I don’t have any hands-on experience with it, just found the docs.  Regardless on the thread pool implementation you gonna use, you’ll then be able to post work to the thread pool dynamically, as you’re traversing the graph. OpenMP also has a thread pool under the hood, but the API is not flexible enough for dynamic parallelism.  16.9k99 gold badges5151 silver badges107107 bronze badges  1  1  OpenMP has had task-based parallelism, which is well suited for dynamic workloads, since version 3.0 (2008), and the OP uses it to accomplish for his task. It is the presence of a critical section in the wrong place that slows things down.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  