 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I'm making a test on a BFS algorithm on CUDA ( wich I know that has some syncronization problems, but it's part of my work to test it anyway ) but i'm having problems on using (or creating?) 1M+ size graphs.  Here's the code I use to create them:  And here's my BFS code (on CUDA):  I'm having a segmantation fault while trying to run it for 1M+ graphs (please note that I used the changed the stack size of the sistem with the command ' ulimit -s 16384 ' on linux)  1 Answer 1  Don't use statically allocated host arrays for the graph, use dynamic memory allocation instead. Your command is setting the stacksize to 16384 kb, but you require something like per graph entry which is probably 22 bytes per entry. It is pretty easy to see where you will run out of stack space with 1 million entries.  68.1k3333 gold badges177177 silver badges250250 bronze badges  3  Yeah, I was running away from that solution (it's a harder implementation) but I think that'll be the only way out of the bugs  How is it a harder implementation? You have to change exactly three lines in you current code, and perhaps add three lines to deallocate the storage afterwards, and you are done.  My point is that handlig with pointers, mainly in parallel algorthms are usually a headache for me..  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  