 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  If I am be adding an unknown number of elements to a List, and that list is only going to be iterated through, would a LinkedList be better than an ArrayList in the particular instance (Using Java, if that has any relevance)  71844 gold badges1111 silver badges3434 bronze badges  3  I'm adding some references to a List. This list is then passes to another object, iterated through once, and then discarded. From what Oscars link lead to, it seems like a LinkedList will be the better option.  stackoverflow is not a good place to find that answer. Use both, benchmark and come to an answer. Something like this might help: javaspecialists.eu/archive/Issue111.html  This is a very good question. However you could help us with your own benchmark though. +1  4 Answers 4  The performance trade-offs between and have been discussed before, but in short: tends to be faster for most real-life usage scenarios. will cause less memory fragmentation and will play nicer with the Garbage Collector, it will use up less memory and allow for faster iteration, and it will be faster for insertions that occur at the end of the list.  So, as long as the insertions in the list always occur at the last position, there's no reason to pick - is the clear winner.  Okay Its been already answered but I will still try to put my point. is faster in iteration than . The reason is same because is backed by an array. Lets try to understand whay array iteration is faster then .  There are 2 factors that work for it  Array is stored as (You can say then what?)  System cache is much faster then accessing memory  But you can ask how Cache fits here. Well check here, CPU tries to take leverage of caches by storing data in cache. It uses Locality of refrence.Now there are 2 techniques which are  Temporal locality If at one point a particular memory location is referenced, then it is likely that the same location will be referenced again in the near future. There is a temporal proximity between the adjacent references to the same memory location. In this case it is common to make efforts to store a copy of the referenced data in special memory storage, which can be accessed faster. Temporal locality is a special case of spatial locality, namely when the prospective location is identical to the present location.  Spatial locality If a particular storage location is referenced at a particular time, then it is likely that nearby memory locations will be referenced in the near future. In this case it is common to attempt to guess the size and shape of the area around the current reference for which it is worthwhile to prepare faster access.  So if one array location is accessed at a time it will load the adjacent memory locations in cache too. But wait it will not load all. It depends on CACHE_LINES. Well define how much bits can be loaded in cache at a time.  So before diving further lest remind what we know  Array is  When one memory location of array is accessed adjacent also loaded in memory  How much array memory locations are loaded in memory is defined by capacity  SO whenever CPU tries to access a memory location it check if that memory is already in cache. If its present it match else its .  So from what we know in case of array there will be less as compared to as in . So it makes sense  In an array with element size k and on a machine with a cache line size of B bytes, iterating through an array of n elements requires the minimum of ceiling(nk/B) cache misses, because its elements occupy contiguous memory locations. This is roughly a factor of B/k better than the number of cache misses needed to access n elements at random memory locations. As a consequence, sequential iteration over an array is noticeably faster in practice than iteration over many other data structures, a property called locality of refrence  For iterating both will have the same O(n) complexity on iterating, ArrayList will take less memory BTW.  Could you explain what O(n) complexity means in this case for a person who does not understand the Big O notation?  @Solace In this case it means there is a linear relationship between the number of elements in the collection and the time it takes to iterate the collection. For example, if you have a list with 10 elements and a list with 20 elements you would expect the list with 20 to take twice as long to iterate. This example might seem quite obvious but not everything scales in a linear fashion, if I have a list and I want to iterate through every possible pair of elements it will have O(n^2) complexity. I.e. the time it takes is proportional to the number of elements you have squared.  I couldn't find any other references on the topic, but isn't iterating over a O(n) and iterating over an O(1)? The iterator returned by calls the method, which is O(n), whereas the iterator returned by simply gets the value from an array, a O(1) operation?  No it's also O(n), LinkedList's iterator holds links to current and previous elements. It cannot be better than O(n) because to iterate over n elements we need to access them at leat once - which is O(n). Asymptotically they both work equally for get(), but remove() operation in LinkedList is O(1) vs O(n) in ArrayList  Arraylist is useful for get random position value, linkedlist useful for insert, remove operate. Above code will show linkedlist very faster than ArrayList, in remove function linkedlist faster than arraylist 1000 times, OMG!!!  Of course, no sane developer would remove elements this way from an . To remove all elements, just call , to remove all elements fulfilling a condition, use  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  