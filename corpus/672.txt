 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I have spent lots of time on this issue. However, I can only find solutions with non-recursive methods for a tree: Non recursive for tree, or a recursive method for the graph, Recursive for graph.  And lots of tutorials (I don't provide those links here) don't provide the approaches as well. Or the tutorial is totally incorrect. Please help me.  Updated:  It's really hard to describe:  If I have an undirected graph:  1-- 2-- 3 --1 is a cycle.  At the step: 'push the neighbors of the popped vertex into the stack', what's the order in which the vertices should be pushed?  If the pushed order is , , , the vertices in the stack are:  After popping the nodes, we get the result: instead of .  It's incorrect. What condition should I add to stop this scenario?  1,92855 gold badges2727 silver badges4646 bronze badges  1  1  Using the algorithm in @amit's excellent answer, I cannot get 4 to appear between 3 and 2. There is one important detail in the algorithm. A node is added to the visited set only when it is actually visited, not when it is pushed on the stack. Marking it visited on stack push would result in the problem you are getting, by preventing treating 3 as a child of 2, or 2 as a child of 3.  13 Answers 13  A DFS without recursion is basically the same as BFS - but use a stack instead of a queue as the data structure.  170k2525 gold badges218218 silver badges320320 bronze badges  11  Well, that thread didn't tell me the specific function implementation like: ; Whatever, I want to know , avoiding to add the same node duplicately as I add the neighbors of one node, the order of the nodes pushed into the stack is right so that as I pop them out, it can get correct order.  @Stallman keeps track of the visited nodes, so that you won't visit the same node twice. As for the order of iteration, if you have a specific order you can implement it by replacing the line with your order of iteration. +1 for a good answer!  I have to implement an executable code to make sure your pseudo-code is correct. Or you can provide specific to proof it.  Won't this code's space complexity use extra memory? I believe the best space complexity for iterative DFS is O(n).  This code is O(n²) for space and time. Consider a complete graph (where every vertex is connected to every other vertex). For all n vertices, every iteration of the while loop will add another list of n vertices to the stack, so there will be O(n²) iterations in total. The space grows a bit slower due of the popping of visited vertices, but it is still O(n²) because it grows as the arithmetic series n+(n-1)+(n-2)+...+2+1. Try this example code.  This is not an answer, but an extended comment, showing the application of the algorithm in @amit's answer to the graph in the current version of the question, assuming 1 is the start node and its neighbors are pushed in the order 2, 4, 3:  Thus applying the algorithm pushing 1's neighbors in the order 2, 4, 3 results in visit order 1, 3, 2, 4. Regardless of the push order for 1's neighbors, 2 and 3 will be adjacent in the visit order because whichever is visited first will push the other, which is not yet visited, as well as 1 which has been visited.  25.1k22 gold badges3535 silver badges6868 bronze badges  10  1  Great explanation. I can't mark this as the answer since no source code is provided.  @Shiro A node may become visited while it is on the stack, so the check for visited during pop is unavoidable. See not 2 in the example. You could also check during push, but it is not necessary to do so.  @Shiro The cost of doing that is an additional conditional branch. Conditional branches can be very expensive through causing a pipeline flush. It is far from obvious that the savings of a simple stack push-pop will cover the cost of the branch, and adding it makes the algorithm more complicated than it needs to be.  1) if the current node is not visited, visit the node and mark it as visited 2) for all its neighbors that haven't been visited, push them to the stack  For example, let's define a GraphNode class in Java:  and here is the DFS without recursion:  We can use the same logic to do DFS recursively, clone graph etc.  Many people will say that non-recursive DFS is just BFS with a stack rather than a queue. That's not accurate, let me explain a bit more.  Recursive DFS  Recursive DFS uses the call stack to keep state, meaning you do not manage a separate stack yourself.  However, for a large graph, recursive DFS (or any recursive function that is) may result in a deep recursion, which can crash your problem with a stack overflow (not this website, the real thing).  Non-recursive DFS  DFS is not the same as BFS. It has a different space utilization, but if you implement it just like BFS, but using a stack rather than a queue, you will use more space than non-recursive DFS.  Why more space?  Consider this:  And compare it with this:  In the first piece of code you are putting all the adjacent nodes in the stack before iterating to the next adjacent vertex and that has a space cost. If the graph is large it can make a significant difference.  What to do then?  If you decide to solve the space problem by iterating over the adjacency list again after popping the stack, that's going to add time complexity cost.  One solution is to add items to the stack one by one, as you visit them. To achieve this you can save an iterator in the stack to resume the iteration after popping.  Lazy way  In C/C++, a lazy approach is to compile your program with a larger stack size and increase stack size via , but that's really lousy. In Java you can set the stack size as a JVM parameter.  Recursion is a way to use the call stack to store the state of the graph traversal. You can use the stack explicitly, say by having a local variable of type , then you won't need the recursion to implement the DFS, but just a loop.  You should have explained the code a bit... OP should understand how the code works... Giving plain code is much like doing their homework...  Python code. The time complexity is O(V+E) where V and E are the number of vertices and edges respectively. The space complexity is O(V) due to the worst-case where there is a path that contains every vertex without any backtracking (i.e. the search path is a linear chain).  The stack stores tuples of the form (vertex, vertex_edge_index) so that the DFS can be resumed from a particular vertex at the edge immediately following the last edge that was processed from that vertex (just like the function call stack of a recursive DFS).  The example code uses a complete digraph where every vertex is connected to every other vertex. Hence it is not necessary to store an explicit edge list for each node, as the graph is an edge list (the graph G contains every vertex).  Output:  Note that time here is measuring V operations and not E. The value is numv*2 because every vertex is considered twice, once on discovery and once on finishing.  Acutally, stack is not well able to deal with discover time and finish time, if we want to implement DFS with stack, and want to deal with discover time and finish time, we would need to resort to another recorder stack, my implementation is shown below, have test correct, below is for case-1, case-2 and case-3 graph.  I think you need to use a boolean array to check if the current node is visited or not earlier.  A recursive algorithm works very well for DFS as we try to plunge as deeply as we can, ie. as soon as we find an un-explored vertex, we're going to explore its FIRST un-explored neighbor right away. You need to BREAK out of the for loop as soon as you find the first un-explored neighbor.  when we reach the end of one path till the last depth, wouldn't the stack be empty if we don't really keep all neighbor in the stack at once?  Using Stack and implementing as done by the call stack in the recursion process-  The Idea is to push a vertex in the stack, and then push its vertex adjacent to it which is stored in a adjacency list at the index of the vertex and then continue this process until we cannot move further in the graph, now if we cannot move ahead in the graph then we will remove the vertex which is currently on the top of the stack as it is unable to take us on any vertex which is unvisited.  Now, using stack we take care of the point that the vertex is only removed from the stack when all the vertices that can be explored from the current vertex have been visited, which was being done by the recursion process automatically.  The above parenthesis show the order in which the vertex is added on the stack and removed from the stack, so a parenthesis for a vertex is closed only when all the vertices that can be visited from it have been done.  (Here I have used the Adjacency List representation and implemented as a vector of list (vector > AdjList) by using C++ STL)  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  