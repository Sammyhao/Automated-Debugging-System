 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I've been coding up a bunch of different binary search tree implementations recently (AVL, splay, treap) and am curious if there's a particularly "good" way to write an iterator to traverse these structures. The solution I've used right now is to have each node in the BST store pointers to the next and previous elements in the tree, which reduces iteration to a standard linked-list iteration. However, I'm not really satisfied with this answer. It increases the space usage of each node by two pointers (next and previous), and in some sense it's just cheating.  I know of a way of building a binary search tree iterator that uses O(h) auxiliary storage space (where h is the height of the tree) by using a stack to keep track of the frontier nodes to explore later on, but I've resisted coding this up because of the memory usage. I was hoping there is some way to build an iterator that uses only constant space.  My question is this - is there a way to design an iterator over a binary search tree with the following properties?  Elements are visited in ascending order (i.e. an inorder traversal)  and queries run in O(1) time.  Memory usage is O(1)  To make it easier, it's fine if you assume that the tree structure isn't changing shape during the iteration (i.e. no insertions, deletions, or rotations), but it would be really cool if there was a solution that could indeed handle this.  339k9494 gold badges838838 silver badges10141014 bronze badges  7  2  If the traversed tree is mutable you can use a trick from TAOCP I.2.3.1 Traversing binary trees, exercise 21. It takes O(N) and O(1) memory. When the algorithm finishes the tree of course won't be changed. It will be the same as it was before.  Why are you worried about the memory overhead of storing a stack of tree nodes in the iterator? It's only O(log n) with the number of elements in the tree, if it's well balanced.  I'm trying to maximize the asymptotic speed of a copy. Using a stack makes iterator copying O(lg n); I'd hope to get O(1) because C++ iterators get copied and passed around a lot.  Henson code seems a bit bugged to me (I'm not completely sure, however). In the BSTIterator<E> & operator++() method, the left descent should be iterative, i.e. you have to traverse to reach the left-est node of m_curNode->GetRight().  8 Answers 8  The simplest possible iterator stores the last seen key, and then on the next iteration, searches the tree for the least upper bound for that key. Iteration is O(log n). This has the advantage of being very simple. If keys are small then the iterators are also small. of course it has the disadvantage of being a relatively slow way of iterating through the tree. It also won't work for non-unique sequences.  Some trees use exactly the implementation you already use, because it's important for their specific use that scanning is very fast. If the number of keys in each node is large, then the penalty of storing sibling pointers isn't too onerous. Most B-Trees use this method.  many search tree implementations keep a parent pointer on each node to simplify other operations. If you have that, then you can use a simple pointer to the last seen node as your iterator's state. at each iteration, you look for the next child in the last seen node's parent. if there are no more siblings, then you go up one more level.  If none of these techniques suit you, you can use a stack of nodes, stored in the iterator. This serves a the same function as the function call stack when iterating through the search tree as normal, but instead of looping through siblings and recursing on children, you push children onto the stack and return each successive sibling.  Creating a stack for iteration through a tree is a terrible idea. It almost defeats the purpose of using a tree. Whatever you are doing to create the stack, do that instead for each iteration step.  As TokenMacGuy mentioned you can use a stack stored in the iterator. Here's a quick tested implementation of this in Java:  Other variation would be to traverse the tree at construction time and save the traversal into a list. You can use the list iterator afterwards.  hasNext is not correctly implemented. It should correctly work after initialization of the iterator.  I think you don't need the current member at all. In the constructor, I would push to the stack all the nodes to the path to the leftmost node. Then, in hasNext() I would only check if the stack is empty.  Ok, I know this is old, but I was asked this in an interview with Microsoft a while back and I decided to work on it a bit. I have tested this and it works quite well.  All sample implementations will require call stack space proportional to the height of the tree. In a poorly balanced tree, this can be quite considerable.  We can remove the stack requirement by maintaining parent pointers in each node, or by threading the tree. In the case of using threads, this will allow for greatly improved inorder traversal, although retrieving the parent node required for preorder and postorder traversal will be slower than a simple stack based algorithm.  In the article there is some pseudocode for iteration with O(1) state, which can be easily adapted to an iterator.  4,34322 gold badges1717 silver badges1818 bronze badges  1  "Threaded BST" - that's what I was looking for, thanks. (Sometimes you do want to visit every node in the thread.)  What about using a depth first search technique. The iterator object just must have a stack of the already visited nodes.  This doesn't use space O(1) because that stack takes up more than a constant amount of space.  If you use stack, you only achieve "Extra memory usage O(h), h is the height of the tree". However, if you want to use only O(1) extra memory, you need to record the Here are the analysis: - If current node has right child: find min of right sub tree - It current node has no right child, you need to look for it from the root, and keep updating it's lowest ancestor, which is its lowest next node  Use O(1) space, which means we will not use O(h) stack.  To begin:  hasNext()? current.val <= endNode.val to check if the tree is fully traversed.  Find min via left-most: We can alwasy look for left-most to find next minimum value.  Once left-most min is checked (name it ). Next min will be 2 cases: If current.right != null, we can keep looking for current.right's left-most child, as next min. Or, we need to look backwards for parent. Use binary search tree to find current's parent node.  Note: when doing binary search for parent, make sure it satisfies parent.left = current.  Because:If parent.right == current, that parent must has been visited before. In binary search tree, we know that parent.val < parent.right.val. We need to skip this special case, since it leads to ifinite loop.  By definition, it is not possible for next() and hasNext() to run in O(1) time. When you are looking at a particular node in a BST, you have no idea the height and structure of the other nodes are, therefore you can not just "jump" to the correct next node.  However, the space complexity can be reduced to O(1) (except for the memory for the BST itself). Here is the way I would do it in C:  The trick is to have both a parent link, and a visited flag for each node. In my opinion, we can argue that this is not additional space usage, it is simply part of the node structure. And obviously, iter_next() must be called without the state of the tree structure changing (of course), but also that the "visited" flags do not change values.  Here is the tester function that calls iter_next() and prints the value each time for this tree:  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  