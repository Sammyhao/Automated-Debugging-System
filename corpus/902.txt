 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I'm currently reading this paper and on page five, it discusses properties of binary heaps that it considers to be common knowledge. However, one of the points they make is something that I haven't seen before and can't make sense of. The authors claim that if you are given a balanced binary heap, you can list the elements of that heap in sorted order in O(log n) time per element using a standard breadth-first search. Here's their original wording:  In a balanced heap, any new element can be inserted in logarithmic time. We can list the elements of a heap in order by weight, taking logarithmic time to generate each element, simply by using breadth first search.  I'm not sure what the authors mean by this. The first thing that comes to mind when they say "breadth-first search" would be a breadth-first search of the tree elements starting at the root, but that's not guaranteed to list the elements in sorted order, nor does it take logarithmic time per element. For example, running a BFS on this min-heap produces the elements out of order no matter how you break ties:  This always lists 100 before either 11 or 12, which is clearly wrong.  Am I missing something? Is there a simple breadth-first search that you can perform on a heap to get the elements out in sorted order using logarithmic time each? Clearly you can do this by destructively modifying heap by removing the minimum element each time, but the authors' intent seems to be that this can be done non-destructively.  339k9494 gold badges838838 silver badges10141014 bronze badges  1  That's weird, simple BFS should take O(1) per element (and it wouldn't work, as you said).  2 Answers 2  You can get the elements out in sorted order by traversing the heap with a priority queue (which requires another heap!). I guess this is what he refers to as a "breadth first search".  I think you should be able to figure it out (given your rep in algorithms) but basically the key of the priority queue is the weight of a node. You push the root of the heap onto the priority queue. Then:  I'm not really sure (at all) if this is what he was referring to but it vaguely fitted the description and there hasn't been much activity so I thought I might as well put it out there.  6,92344 gold badges2222 silver badges3030 bronze badges  1  1  I'm pretty sure you're right. Thanks for posting this! Though I have to admit I'm a bit disappointed... if the way to non-destructively list heap elements is to build and destructively modify the heap, it seems like a cop-out of an answer. (I'm not upset with your answer... sorry... I was just hoping the author was referring to another cool algorithm)  In case that you know that all elements lower than 100 are on left you can go left, but in any case even if you get to 100 you can see that there no elements on left so you go out. In any case you go from node (or any other node) at worst twice before you realise that there are no element you are searching for. Than men that you go in this tree at most 2*log(N) times. This is simplified to log(N) complexity.  Point is that even if you "screw up" and you traverse to "wrong" node you go that node at worst once.  EDIT This is just how heapsort works. You can imagine, that you have to reconstruct heap using N(log n) complexity each time you take out top element.  9,94433 gold badges3131 silver badges5656 bronze badges  1  I'm not sure I understand how this works in the more general case where you know nothing about the tree elements. Can you explain this in a bit more detail?  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  