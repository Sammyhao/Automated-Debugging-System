 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  Linked List  A linked list’s insertion time complexity is O(1) for the actual operation, but requires O(n) time to traverse to the proper position. Most online resources list a linked list’s average insertion time as O(1):  BST  A binary search tree’s insertion requires the traversal of nodes, taking O(log n) time.  Problem  Similar to the nodes of a linked list, an insertion of a node in a BST will simply point the current node’s pointer to the inserted-node, and the inserted-node will point to the current node’s child node.  It seems that for linked list, the actual insertion time is listed as the insertion time complexity, but for BST, the traversal time is listed as the insertion time complexity.  If you don't keep the BST balanced, then it takes O(log n) to find the correct insertion point, and O(1) to add the node. But if you do keep the tree balanced, it's O(log n) to find the correct insertion point, O(1) to add the node, and potentially O(log n) to rebalance the tree. If you don't rebalance after insertion, then the worst case search time can degrade to O(n). In that case, the BST is exactly the same as a linked list. So the key point is that when people talk about a BST, they typically assume that the tree is a balanced BST.  4 Answers 4  A binary search tree is ordered, and it's typically balanced (to avoid worst-case search times), which means that when you insert a value some amount of shuffling has to be done to balance out the tree. That rebalancing takes an average of operations, whereas a Linked List only needs to update a fixed number of pointers once you've found your place to insert an item between nodes.  It reflects the usage. It's O(1) and O(log n) for the operations you'll actually request from them.  With a BST, you'll likely let it manage itself while you stay out of the implementation details. That is, you'll issue commands like or queries like . And those things take O(log n).  With a linked list, you'll more likely manage it yourself, at least the positioning. You wouldn't issue commands like , unless the index is very small or you don't care about performance. You're more likely to issue commands like or , which do only take O(1) time. Note that I took these two from Wikipedia's Linked list operations > Singly linked lists section, which doesn't even have an operation for inserting at a certain position given as an index. Because in reality, you'll manage the "position" (in the form of a node) with the algorithm that uses the linked list, and the time to manage the position is attributed to that algorithm instead. That can btw also be O(1), examples are:  You're building a linked list from an array. You'll do this by keeping a variable referencing the last node. To append the next value/node, insert it after that last node (an O(1) operation indeed), and update your variable to reference the new last node instead (also O(1)).  Imagine you don't find a position with a linear scan but with a hash map, storing references directly to linked list nodes. Then looking up the reference takes O(1) and inserting after the looked-up node also again only takes O(1) time.  If you had shown us some of those "Most online resources list a linked list’s average insertion time as O(1)", we'd likely see that they're indeed showing insertion operations like , not . Edit now that you included some links in the question: My thoughts on those sources regarding the O(1) insertion for linked lists: The first one does point out that it's O(1) only if you already have something like an "iterator to the location". The second one in turn refers to the same Wikipedia section I showed above, i.e., with insertions after a given node or at the beginning of a list. The third one is, well, the worst site about programming I know, so I'm not surprised they just say O(1) without any further information.  Put differently, as I like real-world analogies: If you ask me how much it costs to replace part X inside a car motor, I might say $200, even though the part only costs $5. Because I wouldn't do that myself. I'd let a mechanic do that, and I'd have to pay for their work. But if you ask me how much it costs to replace the bell on a bicycle, I might say $5 when the bell costs $5. Because I'd do the replacing myself.  6,05533 gold badges99 silver badges3030 bronze badges  2  The main distinction you made clear for me is the fact that even though it would, in fact, take O(n) time to traverse a linked list to insert at a position, that is not normally how linked lists are used nor implemented. That's why insertion is listed as O(1) since the normal usage is insertion at the current node of a linked list. Whereas the links I listed mention traversal would take O(n), they don't mention how that is not the usual implementation and usage of a linked list.  @Brendan Yes, that point is rather neglected there, which is why I think it's a good question. I guess the people familiar enough with these things to write about them are often a bit too familiar with them to even wonder about such things anymore :-)  To insert into a linked list, you just need to maintain the end node of the list (assuming you are inserting at the end).  To insert into a binary search tree (BST), and to maintain the BST after insertion, there is no way you can do that in - since the tree might re-balance. This operation is not as simple as inserting into a linked list.  The insertion time of a Linked List is actually depends on where you are inserting and the types of Linked List.  For example consider the following cases:  You are using a single linked list and you are going to insert at the end / middle, you would have running time of O(n) to traverse the list till the end node or middle node.  You are using double linked list (with two pointer first pointer points to head element and second pointer points to last element) and you are going to insert at the end, this time still you would have O(n) time complexity since you need to traverse to the middle of the list using either first or second pointer.  You are using single linked list and you are going to insert at the first position of the list, this time you would have complexity of O(1) since you don't need to traverse any node at all. The same is true for double linked list and insert position at the end of the list.  So you can see in worst cases scenario a Linked list would take O(n) instead of O(1).  Now in case of BST you can come up with O(log n) time if your BST is balanced and not skewed. If your TREE is skewed (where every elements are greater than the prev elements) this time you need to traverse all the nodes to find the insertion position. For example consider your tree is and you are going to insert node , so you need to visit all the nodes to find to insertion position.  Therefore you can see you need to visit all the nodes to find the proper place, if you have n-nodes you would have O(n+1) => O(n) running time complexity.  But if your BST is balanced and not skewed the situation changes dramatically, since every move you can eliminate nodes which is not comes under condition.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  