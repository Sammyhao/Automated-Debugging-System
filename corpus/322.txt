 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I'm looking for a way to remember locations in a doubly-linked list (in hash tables or other data structures).  In C, I would add prev and next pointers to my struct. Then, I could store references to elements of my struct wherever I wanted, and refer to them later. I need only maintain these prev/next pointers to manipulate my linked list, and stored references to locations in the list will stay updated.  What is the C++ approach to this problem?  The end goal is an data structure (which is sequenced, but not ordered, i.e. no comparison function exists, but they are relatively sequenced based on where they are inserted). I need to cheaply insert, delete, move objects as the structure grows. But I also need to cheaply look up each element by some key unrelated to the ordering, and I look up meaningful locations (like head, tail, and various checkpoints in the structure called slices). I need to be able to traverse the sequenced list after looking up a starting place by key or by slice.  Head and tail will be free. I was planning a hash table that maps the keys to list elements, and another hash table that maps slices to list elements.  The conclusion I made was that I would need to maintain both a List and various Maps pointing to the same data to get the performance I need. But doing this by storing iterators in C++ seemed subpar. Instead it seemed easier to reimplement linked list (building it into my class) and using STL maps to point to data.  I was hoping for some input about which is a more fruitful route, or if there is some third plan that better meets my needs. My assumption is that the STL implementation of unordered_map is faster than anything I would implement, but I could match or beat the performance of list since I'm only using a subset of its functionality.  Thanks!  More precise description of my data/performance requirements:  Data will come in with a unique key. I will add it into a queue. I'll need to update/move/remove/delete this data in O(1) based on its unique key. I'll need to insert new data/read data based on metadata stored in other data structures.  I was speaking imprecisely when I said very large list above. The list will definitely fit into memory. Space is cheap enough that it is worth using other data structures to index this list.  Downvotes for title/content/re-ask/all of the above? Sorry guys! Tell me how to fix it.  It's not clear what you intend to do. Do you already have your data structure in C and you want to improve it ? Or do you think of a new data structure, and in this case, why are standard lists not suffiicient to fulfill your needs ? And adapt the title to your question, because when reading it, anyone here will immediately think "opinion based" question.  When I read "ordered data structure", I understand that there is an ordering according to a precise ordering relation. But later you say you want to access values regardless of their ordering. And before that you speak of linked list, which alone are not ordered structures. Which is it?  @Christophe: I know how to solve this problem in C, but I'm new to C++ and looking for the optimal way to get equivalent functionality (hoping there already exists a data structure in STL or Boost that solves what sounds like a common problem). Lists are unacceptable because I need constant time look-ups based on some key (which is not related to the sequencing of the items).  @didierc: Sorry, I butchered some terminology. The items do not have an ordering (there is no comparison function for values or their keys). They do have a sequencing (based on time they were last modified).  2 Answers 2  update/move/remove/delete this data in constant time, using its unique key  According to this the best fit would be the : It works with a key, and uses a hash table to access the elements. In average insert, find, update is constant time (thanks to the hash table), unless the hash function is not appropriate (i.e. worst case if all elements would yield the same hash value, you would have linear time, as in a list, due to the colisions).  This seems also to match your initial intention:  Head and tail will be free. I was planning a hash table that maps the keys to list elements, and another hash table that maps slices to list elements.  Edit: If you need also to master sequencing of elements, independently of their key, you'd need to build a combined container, based on a and an which associates the key to an iterator to the element in the list. You'd then have to manage synchronisation, for example:  insert element: get iterator by inserting element into , then add the iterator to the using the element's key.  remove element: find iterator to element by searching for the key in the , erase element in the using this iterator, and finally erase the key in the unordered_map.  find element: find iterator to element by searching for the key in the  sequential iteration: use the iterator to the begin of the .  58.8k55 gold badges5959 silver badges116116 bronze badges  2  How does this preserve the sequencing of the elements? Each item has an element preceding and following it. I need to be able to traverse these elements based on this sequencing.  The sequencing is not preserved. If you need seqencing you could use a and an unordered_map that would connect the key with an iterator to the list element that you inserted. You'd need however to syncrhonize both structures when you touch the container (ex: insert: first in list, and add iterator to unorederd_map; erase: find list element in undoredered_map and erase it, and then erase the element in the map).  I'd route you to containers to browse... but when you write word 'very large' (and I'm currently Big Data professional) everything changes. Nobody usually gives you good advice for scalability but ... here are points.  What is 'very large' in your case? Does fit your needs? Before 3rd paragraph everything looks suitable if you are not too large. Do your structure fits in memory?  How about your structure aligned to memory manager? Simply -like list with 'prev' and 'next' has serious disadvantage - every element usually is allocated from memory manager. If you are large, this matters and gives your memory over-usage.  What do you expect to be element external reference? If you use pointers - you loose ability to perform optimization on your structure. But probably you don't need it.  Actually you definitely need to consider some 'pools' management if you are really large and indices in such pools can be pretty good references if you modify your structure intensively.  Please consider about large twice. If you mean really large - you need special solution. Especially if your data is larger than your memory. If you are not so large - why not start with just ? When you answer to this question, probably your life could be much more easy ;-).  12.3k77 gold badges6767 silver badges103103 bronze badges  3  I was hasty to use the word large. It's a very manageable size for memory (several GB). But constant time look-ups are very important as I need to handle millions of operations per second. std::list is close to all the functionality I need. I just want to be able to take the reference of an object in the list (say by looking it up in a std::map) and then use the list to find the prev/next items, be able to insert/delete at this location.  Million operations per second... on several GB... What about concurency? Just simple 'std::list' could be not enough.It's special task. I'd recommend more precise profiling. You seem not so aware of real capacity of solution you really need. Please be careful.  Sorry, that's imprecise. Several GB/millions of operations per second across thousands of concurrent threads/data structures. They must be on a single 8-core machine, but any one of the structures is on the order of megabytes and only needs to process thousands of operations per second. It's an as fast as possible requirement, which I've translated into trying to avoid doing something obviously inefficient. Iterating through the list to find an item by its unique key is unacceptable. But there is excess memory for indexing the lists.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  