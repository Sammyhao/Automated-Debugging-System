 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  Is it true that the implementation of BFS, DFS and Dijkstra are almost the same, except that BFS uses queue, DFS uses stack, while Dijkstra uses min priority queue?  More precisely. Can we use the following code for all of BFS, DFS, and Dijkstra, with Q being a queue for BFS, and a stack for DFS, and a min priority queue for Dijkstra? Thanks!  A sub-question to yours: Since DFS can be recursive, does that mean BFS and Dijkstra can be implemented recursively, too?  3 Answers 3  Yes  Let's say we have this graph, and want to find the shortest distances starting at :  Here is a simple interface that allows for the operations needed for the traversal:  And the implementations for queue, stack and priority queue. Note that this interface and classes don't really need to be generic:  Note that for to work as expected, the class needs to provide a method:  Now here's the class. Note that the method takes a instance, which will be used for storing nodes during the traversal.  Finally here's the method, which traverses the same graph 3 times, once with each of the types:  And the results!  Note that DFS will sometimes take the top branch first, yielding different but symmetric results.  Here's what the results look like this on the graph:  4,20211 gold badge2020 silver badges3838 bronze badges  3  The results are pretty confusing because BFS/DFS do not have a notion of weights. Correct BFS: A-B-G-C-H-D-I-E-J-F-K-L. Correct DFS: A-B-C-D-E-F-L-G-H-I-J-K.  I agree this is somewhat confusing. I meant to show the shortest distances as discovered by each type of traversal, though BFS and DFS get the wrong results because they aren't general enough to handle graphs with edge weights as you say.  On the matter of BFS vs. DFS: yes and no, but more "no" than "yes".  If all you care about is the forward traversal order, i.e. the order in which the algorithm discovers the new vertices of the graph, then yes: you can take the classic BFS algorithm, replace the FIFO queue with LIFO stack, and you will get pseudo-DFS algorithm.  However, I call it pseudo-DFS algorithm because it is not really the same as the classic DFS.  The DFS algorithm obtained that way will indeed generate genuine DFS vertex discovery order. However, it will still be different from the classic DFS in some other regadrs. You can find the description of the classic DFS in any book on algorithms (or Wikipedia) and you will see that the structure of the algorithm is notably different from BFS. It is done that way for a reason. The classic DFS offers some additional benefits besides producing the proper DFS vertex discovery order. These additional benefits include  Lower peak memory consumption. In classic DFS implementation the stack size at each moment in time equals the length of the path from the search origin to the current vertex. In pseudo-DFS the stack size at each moment in time equals the sum of the degrees of all vertices from the search origin to the current vertex. This means that the peak memory consumption of pseudo-DFS algorithm will potentially be considerably higher.  For an extreme example, consider a "snowflake" graph consisting of a single vertex in the center directly connected to a 1000 vertices surrounding it. A classic DFS will traverse this graph with maximum stack depth of 1. Meanwhile, a pseudo-DFS will start by pushing all 1000 vertices into the stack (in BFS fashion), resulting in peak stack depth of 1000. That's quite a difference.  Backtracking. A classic DFS algorithm is a genuine recursive algorithm. As a recursive algorithm in addition to the forward traversal order (i.e. vertex discovery order), it also provides you with backward traversal order (backtracking). In the classic DFS you visit each vertex multiple times: first time when you discover it for the very first time, then when you return back from one of its descendant vertices to proceed to the next descendant vertex, and finally for the very last time when you have processed all of its descendants. Many DFS-based algorithms are build on catching and handling these visits. For example, topological sorting algorithm is classic DFS that outputs the vertices in the order of their last DFS visit. The pseudo-DFS algorithm, as I said above, only provides you with clear access to the first event (vertex discovery), but does not register any backtracking events.  298k3939 gold badges502502 silver badges744744 bronze badges  2  It seems the differences you describe are between recursive-DFS and iterative-DFS implementations. So what you call pseudo-DFS is iterative-DFS.  @v.shashenko: No, absolutely not. What I called "true DFS" can be implemented both iteratively and recursively (whatever you prefer) and it will still be significantly different from what I called "pseudo DFS". I have provided an example above ("snowflake" graph, aka star-graph), that immediately illustrates the fundamental difference between true DFS and pseudo-DFS. On star-graph inputs true DFS requires memory while pseudo-DFS requires memory. Such difference cannot be attributed to one algorithm being "iterative" and other "recursive".  Yes this is true. A lot of useful algorithms have similar patterns. For instance, for graph eigenvectors, the Power Iteration algorithm, if you change the starting vector, and the orthogonalizing vector, you get a whole family of useful, but related algorithms. In that case, it's called ABS projection.  In this case they are all built on the "incremental addition"-to-a-tree primitive. It's just how we choose that edge / vertex to add determines the type of tree and hence the type of navigation.  I think there is a bug for the case of Dijkstra. Take the following graph for example. It has three nodes: s, v1, v2 with w(s, v1)=1000, w(s, v2)=500, w(v1, v2)=1. When s is popped out, both v1 and v2 are pushed into Q, both are coloured grey and we set d[v1]=1000 and d[v2]=500. Next, v2 is popped out. At this stage, we should update d[v1] to 501, even though v1 is grey. Otherwise we get wrong d[v1] value. To correct the code, I guess we should update the grey nodes in the for loop, too. Since they are already in Q, we can skip the push step.  I always find the white,grey,black kind of unnecessary. Just keep a visited queue. And in terms of processed it is determined from the order in which you put your process then navigate-next statements in your recursion.  It is confusing to me, too. This coloring scheme was used in the BFS and DFS (but not Dijkstra) of CLRS. However, some other sources (such as topcoder tutorial) use "visited" flag instead. I'm wondering whether we can use the "visited" flag implentation to unite all these three algorithms.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  