 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  Sometimes during programming contests etc., we need a simple working implementation of min priority queue with decrease-key to implement Dijkstra algorithm etc.. I often use set< pair<key_value, ID> > and an array (mapping ID-->key_value) together to achieve that.  Adding an element to the set takes O(log(N)) time. To build a priority queue out of N elements, we simply add them one by one into the set. This takes O(N log(N)) time in total.  The element with min key_value is simply the first element of the set. Probing the smallest element takes O(1) time. Removing it takes O(log(N)) time.  To test whether some ID=k is in the set, we first look up its key_value=v_k in the array and then search the element (v_k, k) in the set. This takes O(log(N)) time.  To change the key_value of some ID=k from v_k to v_k', we first look up its key_value=v_k in the array, and then search the element (v_k, k) in the set. Next we remove that element from the set and then insert the element (v_k', k) into the set. We then update the array, too. This takes O(log(N)) time.  Although the above approach works, most textbooks usually recommend using binary heaps to implement priority queues, as the time of building the binary heaps is just O(N). I heard that there is a built-in priority queue data structure in STL of C++ that uses binary heaps. However, I'm not sure how to update the key_value for that data structure.  What's the easiest and most efficient way of using min priority queue with key update in C++?  5 Answers 5  Although my response will not answer the original question, I think it could be useful for people who reach this question when trying to implement Dijkstra algorithm in C++/Java (like myself), something that was comment by the OP,  in C++ (or in Java) do not provide a operation, as said previously. A nice trick for using those classes when implementing Dijkstra is using "lazy deletion". The main loop of Dijkstra algorithm extracts the next node to be processed from the priority queue, and analises all its adjacent nodes, eventually changing the cost of the minimal path for a node in the priority queue. This is the point where is usually needed in order to update the value of that node.  The trick is not change it at all. Instead, a "new copy" for that node (with its new better cost) is added into the priority queue. Having a lower cost, that new copy of the node will be extracted before the original copy in the queue, so it will be processed earlier.  The problem with this "lazy deletion" is that the second copy of the node, with the higher bad cost, will be eventually extracted from the priority queue. But that will be always occur after the second added copy, with a better cost, has being processed. So the very first thing that the main Dijkstra loop must do when extracting the next node from the priority queue is checking if the node has being previously visited (and we know the shortest path already). It is in that precise moment when we will be doing the "lazy deletion" and the element must be simply ignored.  This solution will have a cost both in memory and time, because the priority queue is storing "dead elements" that we have not removed. But the real cost will be quite small, and programming this solution is, IMHO, easier than any other alternative that tries to simulate the missing operation.  I considered lazy deletion as well. The problem is future insertions are a function of the size of the existing heap, dead elements included. In some cases the performance could be very bad, other cases not so terrible.  @balor123 I'm quite late, but I do wonder: how many elements have you got there? O(log n) operations shouldn't change much (unless you're close to time limits anyway). I assume you'd see the space problem much sooner. Am I missing something?  @domen We need at least O(E+V) space to represent the original graph , so O(E) additional elements won't be a problem.  Well, as Darren already said, doesn't have means for decreasing the priority of an element and neither the removal of an element other than the current min. But the default is nothing more than a simple container adaptor around a that uses the std heap functions from (, and ). So for Dijkstra (where you need priority update) I usually just do this myself and use a simple .  A push is then just the O(log N) operation  Of course for constructing a queue anew from N elements, we don't push them all using this O(log N) operation (making the whole thing O(Nlog N)) but just put them all into the vector followed by a simple O(N)  The min element is a simple O(1)  A pop is the simple O(log N) sequence  So far this is just what usually does under the hood. Now to change an item's priority we just need to change it (however it may be incorporated in the item's type) and make the sequence a valid heap again  I know this is an O(N) operation, but on the other hand this removes any need for keeping track of an item's position in the heap with an additional data structure or (even worse) an augmentation of the items' type. And the performance penalty over a logarithmic priority update is in practice not that signficant, considering the ease of use, compact and linear memory useage of (which impacts runtime, too), and the fact that I often work with graphs that have rather few edges (linear in the vertex count) anyway.  It may not in all cases be the fastest way, but certainly the easiest.  EDIT: Oh, and since the standard library uses max-heaps, you need to use an equivalent to for comparing priorities (however you get them from the items), instead of the default operator.  43.8k1010 gold badges108108 silver badges182182 bronze badges  5  When you say to change an item's priority we just need to change it - do you mean that an search is done to find the item within the heap, the item is updated and then the full heap is re-built (at again)?  @DarrenEngwirda No, I usually have the priority connected to the item anyway (either by being determined from the item directly or by an ID->value array or something the like), which makes updating the priority O(1). If I knew the item's position in the heap (which I don't want to keep track of), then could just use the O(log N) over . The priority is part of the item and not of the heap (of course this requires a non-trivial comparison predicate). By just using the heap doesn't need to know which item's priority changed and we can just do it.  Just because you work with sparse graphs doesn't mean everyone else does. Some of us are doing competitive programming, and the O(N) and O(log N) makes a huge difference.  That's why I didn't claim to provide the fastest and most efficient way for all use-cases. But this certainly is the easiest way to do it in standard C++. But even in other use cases it has to be evaluated if some elaborate Fibonacci or whatever heap provides an actual performance advantage other than looking cool to a competitive programming jury or in a theoretical complexity analysis.  If you're using an O(heap size) operation on update, shouldn't it become worse than simply re-push elements into heap and throw re-pushed elements when pulling elements from heap? It's O(log(heap size)) where heap size is O(|E|), which won't exceed O(|V|).  I don't think the class allows for an efficient implementation of style operations.  I rolled my own binary heap based data structure that supports this, bascially along very similar lines to what you've described for the based priority queue you have:  Maintain a binary heap, sorted by that stores elements of and an array that maps . Within the heap routines etc it's necessary to ensure that the mapping array is kept in-sync with the current heap position of elements. This adds some extra overhead.  Conversion of an array to a heap can be done in according to the standard algorithm described here.  Peeking at the root element is .  Checking if an is currently in the heap just requires an look-up in the mapping array. This also allows peeking at the element corresponding to any .  requires an look-up in the mapping array followed by an update to the heap via .  Pushing a new item onto the heap is as is popping an exitsing item from the heap.  So asymptotically the runtime is improved for a few of the operations compared with the based data structure. Another important improvment is that binary heaps can be implemented on an array, while binary trees are node-based containers. The extra data locality of the binary heap usually translates to improved runtime.  A few issues with this implementation are:  It only allows integer item 's.  It assumes a tight distribution of item 's, starting at zero (otherwise the space complexity of the mapping array blows up!).  You could potentially overcome these issues if you maintained a mapping hash-table, rather than a mapping array, but with a little more runtime overhead. For my use, integer 's have always been enough.  6,74033 gold badges2222 silver badges4242 bronze badges  5  Thanks! Your method agrees with those described in textbooks, and I believe it has optimal performance. Since in practice we have to maintain the ID --> heap_index array, I guess there is no better way than implementing our own binary heap that can achieve the same performance as yours?  @ChongLuo: Since the mapping array needs to be updated within the routines I don't think you can use the routines, I think you need to write you're own. If you were really looking for "the fastest" priority queue for algorithms like Dijkstra's etc it may also be worth checking out some related data structures: Brodal queues, Fibonacci heaps, n-ary heaps, 2-3 heaps to name a few. Some of these data structures are very complex, but offer theoretical improvements to asymptotic complexity...  Measuring this on real graphs (road) and comparing with the lazy deletion method would be interesting. I think I can see why the lazy deletion could be faster - you only modify to_delete set on decrease and there's a check in extract, only touching one element. Conversely, here you need to modify the (probably larger) map for log(n) elements every time you heapify_down, which is in extract, decrease and insert. But maybe the heap will blow up due to containing deleted elements takes over. It depends on the number of decreases. Is there data for road networks on decrease op count?  oh you don't have a to_delete set, you just use visited nodes in Dijkstra as the above answer states. So actually it only depends on the number of decreases and the possible blow up  @Adam: Both the and type strategies can be useful I think. Which is better really depends on your particular application. If you're working with very sparse graphs, may work well (as the size of the heap won't explode). Denser graphs, on the other hand, are a different story. Imagine you have a graph with mean vertex degree of a few hundred -- could lead to a huge space and time blow-up here! Dynamic heaps with a proper operation lead to Dijkstra-type algorithms. Some other answers here are ...  Actually, there is a way to use built-in binary heap from the standard c++ library. The key observation is that the implementation of all heap functions (i.e. std::push_heap, std::pop_heap and std::make_heap) need only the following methods from the stored element of class A:  Constructor  Assignment operator  Comparison operator  It means that assignment operator is called whenever an element is moved in the container storing all heap elements. By overloading this operator you can control the index in the heap. When you have the index you can access the element in the heap, change its value and call std::push_heap to update its position in the heap.  See the simplified implementation of Dijkstra algorithm (without graph):  I know that this solution depends on the inner implementation of the standard library, however it just works for any compiler I am aware of and I used it in programming competitions.  For Decreasing key // can also be use for increasing key  For Inserting in Priority Queue  For Extracting top(min) element  Use this modules in same order  And this code could also be modified for custom data type Here value of long int block is used as key  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  