 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I am doing a college project on library management using doubly linked lists. The doubly linked list holds the ID'S of books whilst being sorted.  I have tried to calculate time elapsed for the worst case for linear vs binary search. Following results:  MY QUESTION:  Even though binary search takes O(logn) comparisons, time elapsed was more due to the fact, it took O(n) traversals until the middle value is found. Is there any better search algorithm for a sorted doubly linked list rather than cumbersome linear search?  My implementation for finding middle value required for binary search:  Is the choice of linked lists your's or is it mandatory? Because, I'm sorry, but I can't really see the point of a binary search in a linked list.  By definition, a linked list does not allow binary search. Only if you have (and maintain) an additional data structure to point to certain points in the list can you speed up searching, but it will never be a binary search.  @-Bob__ the choice isn't mandatory. During the start of the program, the details of a book(like name, author, price, quantity) which are in a file are loaded into dbl(they are stored in a structure and dbl holds the whole structure as its elements). Then all necessary operations like searching are directly performed onto the dbl. I really don't want to make other data structure just for an easier search operation and waste memory. I'm searching for a better search algorithm for a sorted dbl  @user8570772: Given the choice between "easy" and "good", you chose "easy", and now you wonder why it's not good?  For a binary search to be efficient, you have to be able to to get directly to an element--random access. An array is a good example: to access array[N], the program takes the base address of the array and adds N*sizeof(element), and thus knows where to find the data, no iterative traversal. Because as you've observed, the sequential access of a list imposes iterative traversal to find the middle element, which offsets efficiency gains of binary sorting.  3 Answers 3  Your compare would have to to spectacularly slow to justify all that navigation. As it stands I cannot think of a better way than a linear search. If you can alter the structures and CRUD you can certainly index key points ("A" starts here, "B" starts here etc.) and that would allow you to better guess the start and direction of your linear search.  I think you'll find that a linked list, doubly or otherwise, is not a great choice for random lookups or updating in order. Use a B-Tree which seems to be a better fit for the situations you've outlined in your question and comments.  5,42911 gold badge1313 silver badges2626 bronze badges  1  I have a global mid pointer(which holds the middle value), head and tail pointers just to speed up searching operations.  time elapsed was more due to the fact, it took O(n) traversals until the middle value is found.  When you insert new elements in the linked list you could also track the middle element like you're doing with the first and last one. Although the insert function will be more complex. I would use a struct for the linked list with 4 fields:  Yes, I have a global mid pointer holding the middle value. But it becomes more and more complex as it proceeds to find mid value until the requested id is found.EX: Say I want to find 799999 from 1000000 id's ,finding mid pointer becomes hard  It would be expensive if you did it with a while loop that goes through the list halfway. But what I am saying is that when you insert a new element check if the middle one need to update, if so, it would have to move only one position, to next or previous.  Binary search achieves O(log N) complexity in the number of comparisons. When used with an array, accessing the i-th element of the array is performed in constant time, hence not affecting the overall time-complexity.  With a list, singly or doubly linked, accessing the i-th element takes i steps. In your example, accessing the middle element takes a number of steps proportional to the length of the list. As a consequence, the complexity of this search is still O(log N) comparisons but O(n) for the selection of the items to compare, which becomes the dominating factor.  Post as a guest  Not the answer you're looking for? Browse other questions tagged c or ask your own question.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  