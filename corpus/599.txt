 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  I'm writing a simple crawler in Python using the threading and Queue modules. I fetch a page, check links and put them into a queue, when a certain thread has finished processing page, it grabs the next one from the queue. I'm using an array for the pages I've already visited to filter the links I add to the queue, but if there are more than one threads and they get the same links on different pages, they put duplicate links to the queue. So how can I find out whether some url is already in the queue to avoid putting it there again?  25.8k3939 gold badges142142 silver badges224224 bronze badges  1  "array"? In Python? Do you mean "list" or "tuple" or "dictionary"? If you mean "array", which array implementation are you using? numpy?  12 Answers 12  If you don't care about the order in which items are processed, I'd try a subclass of that uses internally:  As Paul McGuire pointed out, this would allow adding a duplicate item after it's been removed from the "to-be-processed" set and not yet added to the "processed" set. To solve this, you can store both sets in the instance, but since you are using the larger set for checking if the item has been processed, you can just as well go back to which will order requests properly.  The advantage of this, as opposed to using a set separately, is that the 's methods are thread-safe, so that you don't need additional locking for checking the other set.  Sure, you could store also the set of all items in the "queue" and modify to first check that set. It's protected by Queue's locking, so there are no race conditions.  The same idea works even if you do care about the order—just use the recipe linked from the docs in place of .  What follows is an improvement over Lukáš Lalinský's latter solution. The important difference is that is overridden in order to ensure is accurate and works as expected.  85.8k5454 gold badges193193 silver badges309309 bronze badges  2  2  With the added advantage of giving you persistence if you choose to use an on disk database. If you hit an unhandled exception you can fix the error and continue where you left off  This is as good as saying ..... N context to the question.. Using SQLite would slow down the whole process overalll  The way I solved this (actually I did this in Scala, not Python) was to use both a Set and a Queue, only adding links to the queue (and set) if they did not already exist in the set.  Both the set and queue were encapsulated in a single thread, exposing only a queue-like interface to the consumer threads.  Edit: someone else suggested SQLite and that is also something I am considering, if the set of visited URLs needs to grow large. (Currently each crawl is only a few hundred pages so it easily fits in memory.) But the database is something that can also be encapsulated within the set itself, so the consumer threads need not be aware of it.  Why only use the array (ideally, a dictionary would be even better) to filter things you've already visited? Add things to your array/dictionary as soon as you queue them up, and only add them to the queue if they're not already in the array/dict. Then you have 3 simple separate things:  Links not yet seen (neither in queue nor array/dict)  Links scheduled to be visited (in both queue and array/dict)  Links already visited (in array/dict, not in queue)  465k7878 gold badges605605 silver badges537537 bronze badges  2  It is important to keep the list of all previously-queued entries (I'd use a set, not a list, not sure what @sam's problem is with set). If you just search the queue for duplicates, you may reprocess an entry that was previously queued and already processed, thus removed from the queue.  Yes, my answer assumed a second data structure in addition to the queue (hence things like 'in both queue and array/dict' and 'in array/dict, not in queue'). You add items to the 'seen' data structure before you queue them. You don't search the queue, you search your 'seen' array. By definition anything in the 'seen' array is either in the queue or already visited; neither of those cases need to be queued again. The main trick is making sure that the check-'seen'-and-queue-if-not-found is atomic.  i think, better call parent functions like this also, _init function doesn't have parameter - receive this  instead of "array of pages already visited" make an "array of pages already added to the queue"  Sadly, I have no enouch rating for comment the best Lukáš Lalinský’s answer.  To add support for and for second variant of Lukáš Lalinský’s SetQueue add else brahch to the if:  Also, instead of a set you might try using a dictionary. Operations on sets tend to get rather slow when they're big, whereas a dictionary lookup is nice and quick.  exactly, that’s misinformation. sets are exactly as fast as dicts (maybe even faster, as no values have to be retrieved/stored)  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  