 your communities  Find centralized, trusted content and collaborate around the technologies you use most.  Connect and share knowledge within a single location that is structured and easy to search.  How do I implement heap in a binary tree. To implement heap, it is important to know the last filled node and the first unoccupied node. This could be done in level ordering of the tree, but then the time complexity will be O(n) just to find the first unoccupied node. So, how to implement heap in a binary tree in O(logn)?  The answer doesn't mention how to find first unoccupied leaf, it just mentions we need to add the new element in the first unoccupied leaf. To my understanding, you need to level order the tree to find the next unoccupied leaf and that will take O(n)  Yes right, I tried to code it. The problem is, if you don't keep a pointer to the parent, then it's a problem to keep track of the next unoccupied leaf. We can maintain a variable to store this info, but calculating this will take O(n). Suppose we are in the 4th level (root is 0) and we have 4 elements starting from left in the 4th level. Now, to get next unoccupied leaf, we need to get the sibling of 2nd level, means go to 1st level parent. This takes O(n) because in a way we are doing level ordering.  8 Answers 8  To implement a heap with a binary tree with O(log n) time complexity, you need to store the total number of nodes as an instance variable.  Suppose we had a heap of 10 total nodes.  If we were to add a node...  We increment the total number of nodes by one. Now we have 11 total nodes. We convert the new total number of nodes (11) to its binary representation: 1011.  With the binary representation of the total nodes (1011), we get rid of the first digit. Afterwards, we use 011 to navigate through the tree to the next location to insert a node in. 0 means to go left and 1 means to go right. Therefore, with 011, we would go left, go right, and go right...which brings us to the next location to insert in.  We examined one node per level, making the time complexity O(log n)  2,12111 gold badge1313 silver badges3131 bronze badges  3  7  That's pretty neat. If you cannot get a binary representation of the number, you can still determine (starting from the root) whether to go left or right. You know how many levels the tree has: level = floor( log(11)/log(2) ) = 3; You know the offset from the left most element in this level: offset = 11 - ( 2^level - 1 ); And how many nodes there can maximally be at this level: max = 2^3 = 8; If the offset is less then half of max, then you are to be in the left subtree, if more than half, go right. As you go down, you update the level and offset and done!  @Bartel Another quick way will be, Step1: If the index is odd - its the right child. This case 11, right child. Step2: Find parent index = floor(index/2). This case floor(11/2) = 5. Step3: Repeat until you get 1, the root of the tree. This case 5 - right child, floor(5/2) = 2, 2 - left child, 2/2 = 1 - root. So we got root, left, right, right. 1......2.....5.......11  You won't implement the heap IN binary tree, because the heap is A binary tree. The heap maintains the following order property - given a node V, its parent is greater or equal to V. Also the heap is complete binary tree. I had ADS course at uni so I will give you my implementation of the heap in Java later in the answer. Just to list the main methods complexities that you obtain:  insert() O(logn)  removeMin() O(logn)  The interesting part that gives you O(logn) performance is the and methods. I will add good explanation about them shortly.  is used when inserting new node to the heap. So when you insert you insert in the last position and then you need to call the like that:  Then the last element is compared against it's parent and if the parent is greater - swap: this is done max logn times where n is the number of nodes. So here comes the logn performance.  For the deletion part - you can remove only min - the highest node. So when you remove it - you have to swap it with the last node - but then you have to maintain the heap property and you have to do a . If the node is greater than it's child swap with the smallest one and so on until you don't have any children left or you don't have smaller children. This can be done max logn times and so here comes the logn performance. You can explain yourself why this operation can be done max logn times by looking in the binary tree pictures here  8,9041919 gold badges6161 silver badges108108 bronze badges  5  Anton, I know the implementation of heap using arrays. I was interested in tree implementation. bdw thanks for the answer.  I'll come to @Anton Belev's defense. S is what I would call an array-based implementation of a binary tree. Each node (array element) has a left and right child which hapen to be found by formula and not by pointer, but I don't think this defines what a binary tree is. Even if I produced a suggestion for the other case, I think the OP should have been more explicit.  when you don't want to use contiguous space in memory to store priority heap, then pointer-based implementation is in use  downvoted because it's an array based implementation, not based on a binary tree which is required in the question  I am answering my own question that takes O(log n), but the limitation is to keep a pointer to the parent. if we don't keep a pointer to the parent, we need approximately O(n). I posted this question to get a solution for O(log n)  Here are the steps to calculate next unoccupied leaf (we have a pointer to the parent node):  This is O(log n), but needs a pointer to the parent.  O(n) solution would be pretty easy, just level order the tree and we get the location of the next unoccupied node.  My question is: how to locate next unoccupied node in O(log n) without using a parent pointer.  1,20133 gold badges1818 silver badges2323 bronze badges  1  I am sorry for the formatting. I did cntrl k to format it and it became like this.  Assuming you want to use a linked binary tree, with no pointers to parent nodes, then the only solution I can think of is keeping a counter of number of children in each node.  This strategy also balances the number of nodes on each side of each subtree, which is beneficial (though extremely slightly).  This is O(log n). Keeping track of count on insertion requires to come all the way up to the roof, but this doesn't change the O(lon n) nature of this operation. Similar thing with deletion.  Other operations are the usual, and preserve their performance characteristics.  Do you need the details or prefer to work them out by yourself?  If you want to use a linked binary tree, with no other information than left and right pointers, then I'd suggest you to initiate a bounty for at least 100,000 points. I'm not saying it's impossible (because I don't have the math to prove it), but I'm saying that this has not been found in several decades (which I do know).  Please note that BTreePrinter is a code I took somewhere in Stackoverflow long back and I modified to use with 2 digit numbers.It will be broken if we move to 3 digit numbers and it is only for simple understanding of how the Heap structure looks.A fix for 3 digit numbers is to keep everything as multiple of 3. Also due credits to Sesh Venugopal for wonderful tutorial on Youtube on Heap data structure  Please add some comments to your code to make it easier to understand. Also explain how your solution is different/better than the others.  By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.  